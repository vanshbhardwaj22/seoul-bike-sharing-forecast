{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c0142f",
   "metadata": {},
   "source": [
    "# Project on Seoul Bike Demand Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4eb3a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97cb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns     # for plotting different types of graph \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split   # testing and training data\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor     # for calculating outliers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler       #  for Scalling features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddef9d9",
   "metadata": {},
   "source": [
    "### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed19b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Asus\\Desktop\\College Projects\\Seoul Bike Prediction Project\\data\\Seoul Bike Data.csv\"\n",
    "\n",
    "df_original = pd.read_csv(data_path , encoding =\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fa85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the given data:\" ,df_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dba8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top columns and rows data is :\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lower columns and rows data is:\")\n",
    "df_original.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a5d30",
   "metadata": {},
   "source": [
    "### Brief Informations of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.describe(include =\"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9faea33",
   "metadata": {},
   "source": [
    "### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cef2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65b554",
   "metadata": {},
   "source": [
    "##### Handling datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac7f45",
   "metadata": {},
   "source": [
    "Handling Date Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Date\"] = pd.to_datetime(df_original[\"Date\"])\n",
    "\n",
    "df_original[\"Day\"] = df_original[\"Date\"].dt.day\n",
    "df_original[\"Weekdays\"] = df_original[\"Date\"].dt.day_name()\n",
    "df_original[\"Month\"] = df_original[\"Date\"].dt.month\n",
    "df_original[\"Year\"] = df_original[\"Date\"].dt.year\n",
    "\n",
    "df_original.drop(\"Date\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4622d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b423844",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d558a",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is an approach that is used to analyze the data and discover trends, patterns, or check assumptions in data with the help of statistical summaries and graphical representationsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bad0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "Month = df_original.groupby(\"Month\").sum().reset_index()\n",
    "sns.barplot(x =\"Month\" , y=\"Rented Bike Count\" , data =Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,7))\n",
    "Month = df_original.groupby(\"Day\").sum().reset_index()\n",
    "sns.barplot(x =\"Day\" , y=\"Rented Bike Count\" , data =Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,6))\n",
    "Month = df_original.groupby(\"Hour\").sum().reset_index()\n",
    "sns.barplot(x =\"Hour\" , y=\"Rented Bike Count\" , data =Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcbba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "sns.barplot(x =\"Holiday\" , y=\"Rented Bike Count\" , data =df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85265ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (6,4))\n",
    "sns.barplot(x =\"Seasons\" , y=\"Rented Bike Count\" , data =df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca5248",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (150,50))\n",
    "sns.barplot(x =\"Rainfall(mm)\" , y=\"Rented Bike Count\" , data =df_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293652be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (40,10))\n",
    "sns.displot(df_original[\"Rented Bike Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfe154",
   "metadata": {},
   "source": [
    "##### Skewed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d4b77",
   "metadata": {},
   "source": [
    "A skewed data distribution is neither symmetric nor normal because the data values trail off more sharply on one side than on the other side. If the value of feature is negative then data is skrewed towards left side whereas if the value of features is positive then the data is skrewed towards right side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f96dc96",
   "metadata": {},
   "source": [
    "Skewed Data is normalized by following meyhods:- Box-cox transform. Log transform. Square root transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.skew().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d7960",
   "metadata": {},
   "source": [
    "##### Multiple Linear Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce72b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "sns.heatmap(df_original.corr() , annot=True , cmap =\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d5590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "def get_vif(df_original):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variables\"] = df_original.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(df_original.values , i) for i in range(df_original.shape[1])]\n",
    "    \n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_for_vif = [\"Day\" ,\"Year\" , \"Rented Bike Count\" , \"Month\" ]\n",
    "\n",
    "get_vif(df_original[[i for i in df_original.describe().columns if i not in not_for_vif]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_for_vif = [\"Day\" ,\"Year\" , \"Rented Bike Count\" , \"Month\" ,\"Dew point temperature(°C)\"]\n",
    "\n",
    "get_vif(df_original[[i for i in df_original.describe().columns if i not in not_for_vif]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb639f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.drop(\"Dew point temperature(°C)\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c856d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4aadad",
   "metadata": {},
   "source": [
    "##### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70f36c",
   "metadata": {},
   "source": [
    "Nominal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Holiday\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Functioning Day\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd996df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Functioning Day\"] = df_original[\"Functioning Day\"].map({\"Yes\":1 ,\"No\":0})\n",
    "df_original[\"Holiday\"] = df_original[\"Holiday\"].map({\"Holiday\":1 ,\"No Holiday\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cc332",
   "metadata": {},
   "source": [
    "One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Seasons\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c748bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original[\"Weekdays\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81222b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seasons = pd.get_dummies(df_orig[\"Seasons\"] ,drop_first=False)\n",
    "df_Weekdays = pd.get_dummies(df_orig[\"Weekdays\"] ,drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seasons.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be233ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Weekdays.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fae991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_orig,df_seasons ,df_Weekdays ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Seasons\" ,\"Weekdays\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b8722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa564690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb408e90",
   "metadata": {},
   "source": [
    "#### Splitting The Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33688b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Rented Bike Count\",axis=1)\n",
    "Y = df[\"Rented Bike Count\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size= 0.2 ,random_state=2023)\n",
    "\n",
    "print(\"Shape of the X_train data:\" , X_train.shape)\n",
    "print(\"Shape of the y_train data:\" , y_train.shape)\n",
    "print(\"Shape of the X_test data:\" , X_test.shape)\n",
    "print(\"Shape of the y_test data:\" , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912a3c6",
   "metadata": {},
   "source": [
    "##### Scalling Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57686bb2",
   "metadata": {},
   "source": [
    "As Machine Learning model learn only numerical value so to avoid any partiallity between any features we use scaling features. This Scaling Features convert Numerical data to numpy format i.e. into mean,standard deviation form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3885b731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b655167",
   "metadata": {},
   "source": [
    "### Training Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8241ff",
   "metadata": {},
   "source": [
    "#### 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3da327",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1275f2c",
   "metadata": {},
   "source": [
    "#####  Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = mean_squared_error(y_test,y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_test,y_pred)\n",
    "R2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(\"Mean squared Error of given data is :\" ,MSE)\n",
    "print(\"Root Mean squared Error of given data is :\" ,RMSE)\n",
    "print(\"Mean absolute Error of given data is :\" ,MAE)\n",
    "print(\"R2 score of given data is :\" ,R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_metrics(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(MSE)\n",
    "    mae = mean_absolute_error(y_test,y_pred) \n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "   \n",
    "\n",
    "    print(\"Mean squared Error  of\",model_name, \"is :\", round(mse,3))\n",
    "    print(\"Root Mean squared Error of\",model_name, \"is :\" ,round(rmse,3))\n",
    "    print(\"Mean absolute Error of\",model_name, \"is :\" ,round(mae,3))\n",
    "    print(\"R2 score of\",model_name, \"is :\" ,round(r2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_metrics(y_test,y_pred, \"Linear Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4683a",
   "metadata": {},
   "source": [
    "#### 2. Training Multi Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge ,Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid = Ridge().fit(X_train,y_train)\n",
    "y_pred_Ridge =rid.predict(X_test)\n",
    "\n",
    "las = Lasso().fit(X_train,y_train)\n",
    "y_pred_Lasso = las.predict(X_test)\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "poly_r = LinearRegression().fit(X_train_poly ,y_train)\n",
    "y_pred_PolynomialFeatures = poly_r.predict(X_test_poly)\n",
    "\n",
    "svc = SVC().fit(X_train,y_train)\n",
    "y_pred_SVC = svc.predict(X_test)\n",
    "\n",
    "KNR = KNeighborsRegressor().fit(X_train,y_train)\n",
    "y_pred_KNeighborsRegressor = KNR.predict(X_test)\n",
    "\n",
    "DTR = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "y_pred_DecisionTreeRegressor = DTR.predict(X_test)\n",
    "\n",
    "RFR = RandomForestRegressor().fit(X_train,y_train)\n",
    "y_pred_RandomForestRegressor = RFR.predict(X_test)\n",
    "\n",
    "XGBR = XGBRegressor().fit(X_train,y_train)\n",
    "y_pred_XGBRegressor = XGBR.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d198e7",
   "metadata": {},
   "source": [
    "#### Evaluating Multi Machine Learning Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf21df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_metrics(y_test,y_pred_Ridge, \"Ridge\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_Lasso, \"Lasso\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_PolynomialFeatures, \"Polynomial Features\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_SVC, \"SVC\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_KNeighborsRegressor, \"KNeighborsRegressor\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_DecisionTreeRegressor, \"DecisionTreeRegressor\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_RandomForestRegressor, \"RandomForestRegressor\")\n",
    "print(\"...\")\n",
    "det_metrics(y_test,y_pred_XGBRegressor, \"XGBRegressor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c65cc9",
   "metadata": {},
   "source": [
    "#### 3. Visualize The pattern of Prediction Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316a0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred)\n",
    "plt.xlabel(\"Ground Truth\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.title(\"Linear Regression Tested VS Prediction Plot\")\n",
    "plt.show()\n",
    "plt.figure(figsize =(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred_RandomForestRegressor)\n",
    "plt.xlabel(\"Ground Truth\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.title(\"Random Forest Regressor Tested VS Prediction Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafdc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,y_pred_XGBRegressor)\n",
    "plt.xlabel(\"Ground Truth\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.title(\"XG Boost Regressor Tested VS Prediction Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc24a7",
   "metadata": {},
   "source": [
    "### Hyper Parameters Tuning for Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators =[int(x) for x in np.linspace(start =200,stop=2000,num=10)]\n",
    "\n",
    "# Number of features in each split\n",
    "max_features = [\"auto\",\"sqrt\"]\n",
    "\n",
    "# Number of levels in every decision tree\n",
    "max_depth = [int(x) for x in np.linspace(10,120,num=12)]\n",
    "\n",
    "# Number of samples requires to split a single node\n",
    "min_samples_split = [2,5,10]\n",
    "\n",
    "# Number of samples requires to split a single leaf\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "# Methods for selecting samples for training\n",
    "bootstrap = [True,False]\n",
    "\n",
    "# Creating Random Grid\n",
    "Random_grid = { \"n_estimators\": n_estimators , \"max_features\":max_features , \"max_depth\" :max_depth ,\n",
    "              \"min_samples_split\" :min_samples_split , \"min_samples_leaf\" : min_samples_leaf , \"bootstrap\" :bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc05205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "RFR = RandomForestRegressor()\n",
    "RFR_random = RandomizedSearchCV( estimator = RFR,\n",
    "    param_distributions =Random_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42)\n",
    "RFR_random.fit(X_train,y_train)\n",
    "y_pred_RFR_random = RFR_random.predict(X_test)\n",
    "\n",
    "print(\"Time taken by the system for training the data through Randomized Search CV :\" ,time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc570e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_metrics(y_test,y_pred_RFR_random, \"Random Forest Regressor Fine Tune\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a781764",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_tuned = RandomForestRegressor(n_estimators = 800 ,max_depth =100,\n",
    "              min_samples_split =2 ,  min_samples_leaf=1 ,bootstrap=True)\n",
    "RFR_tuned.fit(X_train,y_train)\n",
    "y_pred_RFR_tuned = RFR_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_metrics(y_test,y_pred_RFR_tuned, \"Random Forest Regressor Fine Tune With Best Parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfb003",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2931d0",
   "metadata": {},
   "source": [
    "### Hyper Parameters Tuning for XG Boost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef441c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "n_estimators =  [int(x) for x in np.linspace(start =200,stop=2000,num=10)]\n",
    "max_depth =  [int(x) for x in np.linspace(10,120,num=12)]\n",
    "colsample_bytree = np.arange(0.4,1.0,0.1)\n",
    "colsample_bylevel =  np.arange(0.4,1.0,0.1)\n",
    "subsample = np.arange(0.5,1.0,0.1)\n",
    "learning_rate = [0.01,0.1,0.2,0.3]\n",
    "\n",
    "params = { \"n_estimators\": n_estimators , \"colsample_bytree\":colsample_bytree , \"max_depth\" :max_depth ,\n",
    "              \"colsample_bylevel\" :colsample_bylevel , \"subsample\" : subsample , \"learning_rate\" :learning_rate}\n",
    "\n",
    "XGBR = XGBRegressor(seed=20)\n",
    "\n",
    "RSCV = RandomizedSearchCV( estimator = XGBR,\n",
    "    param_distributions =params,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring = 'neg_mean_squared_error')\n",
    "\n",
    "\n",
    "RSCV.fit(X_train,y_train)\n",
    "y_pred_XGB_random= RSCV.predict(X_test)\n",
    "\n",
    "print(\"Time taken by the system for training the XG Boost Model through Randomized Search CV :\" ,time.time()-start_time)\n",
    "\n",
    "det_metrics(y_test,y_pred_XGB_random, \"XG Boost Regressor With Best Parameters\")\n",
    "\n",
    "print(\"Best Parameters are :\", RSCV.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_tune = XGBRegressor(subsample = 0.5,\n",
    "                          n_estimators = 1200, max_depth =  90, learning_rate =  0.01, \n",
    "                          colsample_bytree =  0.8999999999999999, \n",
    "                          colsample_bylevel = 0.8999999999999999)\n",
    "xgbr_tune.fit(X_train,y_train)\n",
    "y_pred_xgbr_tune = xgbr_tune.predict(X_test)\n",
    "\n",
    "det_metrics(y_test,y_pred_xgbr_tune, \"XG Boost Regressor Fine Tune With Best Parameters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123748d",
   "metadata": {},
   "source": [
    "### Save ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7687030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dir = r\"C:\\Users\\Asus\\Desktop\\College Projects\\Seoul Bike Prediction Project\\models\"\n",
    "model_file_name = \"XGBoost_Regressor_r2_0_929_v1.pkl\"\n",
    "\n",
    "model_file_path = os.path.join(dir , model_file_name)\n",
    "\n",
    "pickle.dump(xgbr_tune , open(model_file_path , \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0 ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a513728",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668071ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[3,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feadd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f89ed0e",
   "metadata": {},
   "source": [
    "### Dumping Scaling Features Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc501ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_dump_path = r\"C:\\Users\\Asus\\Desktop\\College Projects\\Seoul Bike Prediction Project\\models\\sc.pkl\"\n",
    "\n",
    "pickle.dump(sc ,open(sc_dump_path ,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a09e8",
   "metadata": {},
   "source": [
    "## Different Algorithm Analysis and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- Regression Models to Compare ---\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# You can add more, e.g., from xgboost import XGBRegressor, from lightgbm import LGBMRegressor\n",
    "\n",
    "# --- Hypothetical Data Loading and Preprocessing (Replace with your actual data) ---\n",
    "# This part simulates having your preprocessed data ready, similar to the end\n",
    "# of your 'Seoul Bike Sharing Demand Prediction.ipynb' notebook.\n",
    "# You would load your 'Seoul Bike Data.csv', perform all cleaning, feature engineering,\n",
    "# and one-hot encoding, and then separate features (X) and target (y).\n",
    "\n",
    "# For demonstration, let's create some dummy data that resembles your problem\n",
    "# In a real scenario, X would have 24 features and y would be 'Rented Bike Count'\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "num_features = 24\n",
    "X = pd.DataFrame(np.random.rand(num_samples, num_features), columns=[f'feature_{i}' for i in range(num_features)])\n",
    "y = pd.Series(np.random.randint(0, 3000, num_samples)) # Dummy bike counts\n",
    "\n",
    "# If you want to use your actual preprocessed DataFrame from your first notebook:\n",
    "# df_processed = pd.read_csv('your_preprocessed_data.csv') # Load your clean data\n",
    "# X = df_processed.drop('Rented Bike Count', axis=1) # Adjust target column name if different\n",
    "# y = df_processed['Rented Bike Count']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "# It's important to use the same split for all models for fair comparison\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling numerical features (if not already done in your preprocessing pipeline)\n",
    "# Ensure StandardScaler is fitted ONLY on training data and then transform both train/test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier inspection and plotting (optional, but good practice)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "\n",
    "# --- 1. Define Algorithms to Test ---\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(random_state=42), # Added random_state for reproducibility\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    # \"XGBoost Regressor\": XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42),\n",
    "    # \"LightGBM Regressor\": LGBMRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# --- Store Results ---\n",
    "results = pd.DataFrame(columns=['Model', 'R-squared', 'MAE', 'MSE', 'RMSE'])\n",
    "\n",
    "# --- 2. Train, Evaluate, and Visualize Each Model ---\n",
    "print(\"--- Model Training, Evaluation, and Visualization ---\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # --- 3. Calculate Evaluation Metrics ---\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    print(f\"{name} Performance:\")\n",
    "    print(f\"  R-squared (R2): {r2:.4f}\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "    # Store results\n",
    "    results.loc[len(results)] = [name, r2, mae, mse, rmse]\n",
    "\n",
    "    # --- 4. Error Checking Visualization ---\n",
    "\n",
    "    # Plotting Actual vs. Predicted Values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Diagonal line\n",
    "    plt.xlabel(\"Actual Bike Count\")\n",
    "    plt.ylabel(\"Predicted Bike Count\")\n",
    "    plt.title(f\"{name}: Actual vs. Predicted Bike Count\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Residuals (Prediction Errors)\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.6)\n",
    "    plt.axhline(y=0, color='r', linestyle='--', lw=2) # Zero error line\n",
    "    plt.xlabel(\"Predicted Bike Count\")\n",
    "    plt.ylabel(\"Residuals (Actual - Predicted)\")\n",
    "    plt.title(f\"{name}: Residuals Plot\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Distribution of Residuals\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(residuals, kde=True, bins=30)\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(f\"{name}: Distribution of Residuals\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Summary of All Models ---\")\n",
    "print(results.set_index('Model'))\n",
    "\n",
    "# Optional: Visualize overall performance comparison\n",
    "results_melted = results.melt(id_vars='Model', var_name='Metric', value_name='Value')\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x='Model', y='Value', hue='Metric', data=results_melted[results_melted['Metric'].isin(['R-squared', 'MAE', 'RMSE'])])\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd072f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c729dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
